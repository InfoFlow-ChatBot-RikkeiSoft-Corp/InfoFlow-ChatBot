{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain loader\n",
        "Document loaders\n",
        "- csv\n",
        "- file directory\n",
        "- html\n",
        "- json\n",
        "- markdown\n",
        "- pdf"
      ],
      "metadata": {
        "id": "bgRvKvY9UrA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## csv\n",
        "A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.\n",
        "\n",
        "Load CSV data with a single row per document."
      ],
      "metadata": {
        "id": "nrpH_OAJVPTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "\n",
        "loader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv')\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "vGrg98fvVOkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VitF0lprUoq7"
      },
      "outputs": [],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customizing the CSV parsing and loading\n",
        "See the csv module documentation for more information of what csv args are supported.\n"
      ],
      "metadata": {
        "id": "Bolgp2_4VpfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv', csv_args={\n",
        "    'delimiter': ',',\n",
        "    'quotechar': '\"',\n",
        "    'fieldnames': ['MLB Team', 'Payroll in millions', 'Wins']\n",
        "})\n",
        "\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "M0Lskc4TVy_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specify a column to identify the document source\n",
        "Use the `source_column` argument to specify a source for the document created from each row. Otherwise file_path will be used as the source for all documents created from the CSV file.\n",
        "\n",
        "This is useful when using documents loaded from CSV files for chains that answer questions using sources."
      ],
      "metadata": {
        "id": "IfQRx_8EV5PS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv', source_column=\"Team\")\n",
        "\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "lQUHN_HtV244"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## file directory\n",
        "This covers how to load all documents in a directory.\n",
        "Under the hood, by default this uses the UnstructuredLoader."
      ],
      "metadata": {
        "id": "5EBUAJK1WG6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader"
      ],
      "metadata": {
        "id": "fYmXQM4VWC3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the glob parameter to control which files to load. Note that here it doesn't load the .rst file or the .html files."
      ],
      "metadata": {
        "id": "3O_ssNLNWR8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader('../', glob=\"**/*.md\")"
      ],
      "metadata": {
        "id": "gMNhIC2GWTuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "ncRw4jzvWaEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "id": "rB6HHlSyWbv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show a progress bar\n",
        "By default a progress bar will not be shown. To show a progress bar, install the tqdm library (e.g. `pip install tqdm`), and set the show_progress parameter to True."
      ],
      "metadata": {
        "id": "pOF28S2bWe63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader('../', glob=\"**/*.md\", show_progress=True)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "kz_i7DOCWdSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "    Requirement already satisfied: tqdm in /Users/jon/.pyenv/versions/3.9.16/envs/microbiome-app/lib/python3.9/site-packages (4.65.0)\n",
        "\n",
        "\n",
        "    0it [00:00, ?it/s]\n",
        "    ```\n",
        "    "
      ],
      "metadata": {
        "id": "QCWQQvS9WwQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use multithreading\n",
        "\n",
        "By default the loading happens in one thread. In order to utilize several threads set the use_multithreading flag to true.\n",
        "\n"
      ],
      "metadata": {
        "id": "U_3ri0j3W1iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader('../', glob=\"**/*.md\", use_multithreading=True)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "49zfuTrRWvnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change loader class\n",
        "By default this uses the UnstructuredLoader class. However, you can change up the type of loader pretty easily."
      ],
      "metadata": {
        "id": "x7xXBqTSW_b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n"
      ],
      "metadata": {
        "id": "B8-H6ktxW9QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader('../', glob=\"**/*.md\", loader_cls=TextLoader)"
      ],
      "metadata": {
        "id": "zMjnHoqkXFdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "8ZqHo2ggXHD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you need to load Python source code files, use the PythonLoader."
      ],
      "metadata": {
        "id": "nJieJXJjXNJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PythonLoader\n",
        "\n",
        "loader = DirectoryLoader('../../../../../', glob=\"**/*.py\", loader_cls=PythonLoader)\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "len(docs)"
      ],
      "metadata": {
        "id": "_MVWn5S7XKEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auto-detect file encodings with TextLoader\n",
        "\n",
        "In this example we will see some strategies that can be useful when loading a large list of arbitrary files from a directory using the TextLoader class.\n",
        "\n",
        "First to illustrate the problem, let's try to load multiple texts with arbitrary encodings."
      ],
      "metadata": {
        "id": "Pzcjmz--XZYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '../../../../../tests/integration_tests/examples'\n",
        "loader = DirectoryLoader(path, glob=\"**/*.txt\", loader_cls=TextLoader)"
      ],
      "metadata": {
        "id": "16NuB-9iXWY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. Default Behavior"
      ],
      "metadata": {
        "id": "Y2Z4tqBLXk3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader.load()"
      ],
      "metadata": {
        "id": "vrI2Rp5HXm1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. Silent fail\n",
        "\n",
        "We can pass the parameter silent_errors to the DirectoryLoader to skip the files which could not be loaded and continue the load process."
      ],
      "metadata": {
        "id": "4r16VMy2X7yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader(path, glob=\"**/*.txt\", loader_cls=TextLoader, silent_errors=True)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "SVy3OdD2X9er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```     Error loading ../../../../../tests/integration_tests/examples/example-non-utf8.txt ```\n",
        "\n",
        "```\n",
        "doc_sources = [doc.metadata['source']  for doc in docs]\n",
        "doc_sources\n",
        "```\n",
        "\n",
        "```\n",
        "    ['../../../../../tests/integration_tests/examples/whatsapp_chat.txt',\n",
        "     '../../../../../tests/integration_tests/examples/example-utf8.txt']\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sXntSamQYEXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C. Auto detect encodings\n",
        "\n",
        "We can also ask TextLoader to auto detect the file encoding before failing, by passing the autodetect_encoding to the loader class."
      ],
      "metadata": {
        "id": "SKudSGlTYQvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_loader_kwargs={'autodetect_encoding': True}\n",
        "loader = DirectoryLoader(path, glob=\"**/*.txt\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "EG95h_a2YUtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_sources = [doc.metadata['source']  for doc in docs]\n",
        "doc_sources"
      ],
      "metadata": {
        "id": "6QN8JRkCYWsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "    ['../../../../../tests/integration_tests/examples/example-non-utf8.txt',\n",
        "     '../../../../../tests/integration_tests/examples/whatsapp_chat.txt',\n",
        "     '../../../../../tests/integration_tests/examples/example-utf8.txt']\n",
        "```\n"
      ],
      "metadata": {
        "id": "7Ocj1DwOYYiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HTML\n",
        "The HyperText Markup Language or HTML is the standard markup language for documents designed to be displayed in a web browser.\n",
        "\n",
        "This covers how to load HTML documents into a document format that we can use downstream."
      ],
      "metadata": {
        "id": "uRefqOMBYfHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
        "\n",
        "loader = UnstructuredHTMLLoader(\"example_data/fake-content.html\")\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "k8qFbPOBYpsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading HTML with BeautifulSoup4\n",
        "\n",
        "We can also use BeautifulSoup4 to load HTML documents using the BSHTMLLoader. This will extract the text from the HTML into page_content, and the page title as title into metadata."
      ],
      "metadata": {
        "id": "7azipoG9YwCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import BSHTMLLoader\n",
        "\n",
        "loader = BSHTMLLoader(\"example_data/fake-content.html\")\n",
        "data = loader.load()\n",
        "data"
      ],
      "metadata": {
        "id": "Ffq-R8bcY2MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JSON\n",
        "JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).\n",
        "\n",
        "JSON Lines is a file format where each line is a valid JSON value.\n",
        "\n",
        "The `JSONLoader` uses a specified jq schema to parse the JSON files. It uses the jq python package. Check this manual for a detailed documentation of the jq syntax."
      ],
      "metadata": {
        "id": "UDSi3X_zY6hU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install jq"
      ],
      "metadata": {
        "id": "gbUW_RNQY4NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import JSONLoader\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "file_path='./example_data/facebook_chat.json'\n",
        "data = json.loads(Path(file_path).read_text())\n",
        "\n",
        "pprint(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "nLOcXVaGZE5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "    {'image': {'creation_timestamp': 1675549016, 'uri': 'image_of_the_chat.jpg'},\n",
        "     'is_still_participant': True,\n",
        "     'joinable_mode': {'link': '', 'mode': 1},\n",
        "     'magic_words': [],\n",
        "     'messages': [{'content': 'Bye!',\n",
        "                   'sender_name': 'User 2',\n",
        "                   'timestamp_ms': 1675597571851},\n",
        "                  {'content': 'Oh no worries! Bye',\n",
        "                   'sender_name': 'User 1',\n",
        "                   'timestamp_ms': 1675597435669},\n",
        "                  {'content': 'No Im sorry it was my mistake, the blue one is not '\n",
        "                              'for sale',\n",
        "                   'sender_name': 'User 2',\n",
        "                   'timestamp_ms': 1675596277579},\n",
        "                  {'content': 'I thought you were selling the blue one!',\n",
        "                   'sender_name': 'User 1',\n",
        "                   'timestamp_ms': 1675595140251},\n",
        "                  {'content': 'Im not interested in this bag. Im interested in the '\n",
        "                              'blue one!',\n",
        "                   'sender_name': 'User 1',\n",
        "                   'timestamp_ms': 1675595109305},\n",
        "                  {'content': 'Here is $129',\n",
        "                   'sender_name': 'User 2',\n",
        "                   'timestamp_ms': 1675595068468},\n",
        "                  {'photos': [{'creation_timestamp': 1675595059,\n",
        "                               'uri': 'url_of_some_picture.jpg'}],\n",
        "                   'sender_name': 'User 2',\n",
        "                   'timestamp_ms': 1675595060730},\n",
        "                  {'content': 'Online is at least $100',\n",
        "                   'sender_name': 'User 2',\n",
        "                   'timestamp_ms': 1675595045152},\n",
        "                  {'content': 'How much do you want?',\n",
        "                   'sender_name': 'User 1',\n",
        "                   'timestamp_ms': 1675594799696},\n",
        "                  {'content': 'Goodmorning! $50 is too low.',\n",
        "                   'sender_name': 'User 2',\n",
        "                   'timestamp_ms': 1675577876645},\n",
        "                  {'content': 'Hi! Im interested in your bag. Im offering $50. Let '\n",
        "                              'me know if you are interested. Thanks!',\n",
        "                   'sender_name': 'User 1',\n",
        "                   'timestamp_ms': 1675549022673}],\n",
        "     'participants': [{'name': 'User 1'}, {'name': 'User 2'}],\n",
        "     'thread_path': 'inbox/User 1 and User 2 chat',\n",
        "     'title': 'User 1 and User 2 chat'}\n",
        "```"
      ],
      "metadata": {
        "id": "0W4mc_iQZJbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using JSONLoader\n",
        "Suppose we are interested in extracting the values under the content field within the messages key of the JSON data. This can easily be done through the JSONLoader as shown below."
      ],
      "metadata": {
        "id": "gaczt0VKZPTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### json file"
      ],
      "metadata": {
        "id": "a58XKIBuZaBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = JSONLoader(\n",
        "    file_path='./example_data/facebook_chat.json',\n",
        "    jq_schema='.messages[].content',\n",
        "    text_content=False)\n",
        "\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "3EW7fSaMZMvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(data)"
      ],
      "metadata": {
        "id": "t9JnOfObZfen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "    [Document(page_content='Bye!', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 1}),\n",
        "     Document(page_content='Oh no worries! Bye', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 2}),\n",
        "     Document(page_content='No Im sorry it was my mistake, the blue one is not for sale', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 3}),\n",
        "     Document(page_content='I thought you were selling the blue one!', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 4}),\n",
        "     Document(page_content='Im not interested in this bag. Im interested in the blue one!', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 5}),\n",
        "     Document(page_content='Here is $129', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 6}),\n",
        "     Document(page_content='', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 7}),\n",
        "     Document(page_content='Online is at least $100', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 8}),\n",
        "     Document(page_content='How much do you want?', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 9}),\n",
        "     Document(page_content='Goodmorning! $50 is too low.', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 10}),\n",
        "     Document(page_content='Hi! Im interested in your bag. Im offering $50. Let me know if you are interested. Thanks!', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 11})]\n",
        "\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "aV0JAJxXZhDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### json lines file\n",
        "If you want to load documents from a JSON Lines file, you pass json_lines=True and specify jq_schema to extract page_content from a single JSON object."
      ],
      "metadata": {
        "id": "fAJiWAMmZnN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './example_data/facebook_chat_messages.jsonl'\n",
        "pprint(Path(file_path).read_text())"
      ],
      "metadata": {
        "id": "--hMPebSZge6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "    ('{\"sender_name\": \"User 2\", \"timestamp_ms\": 1675597571851, \"content\": \"Bye!\"}\\n'\n",
        "     '{\"sender_name\": \"User 1\", \"timestamp_ms\": 1675597435669, \"content\": \"Oh no '\n",
        "     'worries! Bye\"}\\n'\n",
        "     '{\"sender_name\": \"User 2\", \"timestamp_ms\": 1675596277579, \"content\": \"No Im '\n",
        "     'sorry it was my mistake, the blue one is not for sale\"}\\n')\n",
        "```\n"
      ],
      "metadata": {
        "id": "Hw6W4h6uZvI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = JSONLoader(\n",
        "    file_path='./example_data/facebook_chat_messages.jsonl',\n",
        "    jq_schema='.content',\n",
        "    text_content=False,\n",
        "    json_lines=True)\n",
        "\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "h4n9cyJoZyap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "    [Document(page_content='Bye!', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}),\n",
        "     Document(page_content='Oh no worries! Bye', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat_messages.jsonl', 'seq_num': 2}),\n",
        "     Document(page_content='No Im sorry it was my mistake, the blue one is not for sale', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat_messages.jsonl', 'seq_num': 3})]\n",
        "```\n"
      ],
      "metadata": {
        "id": "n65Eqr0UZ4IZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another option is set jq_schema='.' and provide content_key:"
      ],
      "metadata": {
        "id": "lP3tIds_Z8UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = JSONLoader(\n",
        "    file_path='./example_data/facebook_chat_messages.jsonl',\n",
        "    jq_schema='.',\n",
        "    content_key='sender_name',\n",
        "    json_lines=True)\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "pprint(data)"
      ],
      "metadata": {
        "id": "PVi02GZmZ3FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ```\n",
        "    [Document(page_content='User 2', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}),\n",
        "     Document(page_content='User 1', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat_messages.jsonl', 'seq_num': 2}),\n",
        "     Document(page_content='User 2', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat_messages.jsonl', 'seq_num': 3})]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "PLMjAX50aCe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extracting metadata\n",
        "\n",
        "Generally, we want to include metadata available in the JSON file into the documents that we create from the content.\n",
        "\n",
        "The following demonstrates how metadata can be extracted using the JSONLoader.\n",
        "\n",
        "There are some key changes to be noted. In the previous example where we didn't collect the metadata, we managed to directly specify in the schema where the value for the page_content can be extracted from."
      ],
      "metadata": {
        "id": "qaASiCg7aHo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ".messages[].content"
      ],
      "metadata": {
        "id": "1XnnBcjcaF5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the current example, we have to tell the loader to iterate over the records in the messages field. The jq_schema then has to be:"
      ],
      "metadata": {
        "id": "29Wkl0wSaQsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ".messages[]\n",
        "\n"
      ],
      "metadata": {
        "id": "nqJgqUrlaSkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This allows us to pass the records (dict) into the metadata_func that has to be implemented. The metadata_func is responsible for identifying which pieces of information in the record should be included in the metadata stored in the final Document object.\n",
        "\n",
        "Additionally, we now have to explicitly specify in the loader, via the content_key argument, the key from the record where the value for the page_content needs to be extracted from."
      ],
      "metadata": {
        "id": "VveHkU67aT0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the metadata extraction function.\n",
        "def metadata_func(record: dict, metadata: dict) -> dict:\n",
        "\n",
        "    metadata[\"sender_name\"] = record.get(\"sender_name\")\n",
        "    metadata[\"timestamp_ms\"] = record.get(\"timestamp_ms\")\n",
        "\n",
        "    return metadata\n",
        "\n",
        "\n",
        "loader = JSONLoader(\n",
        "    file_path='./example_data/facebook_chat.json',\n",
        "    jq_schema='.messages[]',\n",
        "    content_key=\"content\",\n",
        "    metadata_func=metadata_func\n",
        ")\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "pprint(data)"
      ],
      "metadata": {
        "id": "VKk4WcI_aWqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "    [Document(page_content='Bye!', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 1, 'sender_name': 'User 2', 'timestamp_ms': 1675597571851}),\n",
        "     Document(page_content='Oh no worries! Bye', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 2, 'sender_name': 'User 1', 'timestamp_ms': 1675597435669}),\n",
        "     Document(page_content='No Im sorry it was my mistake, the blue one is not for sale', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 3, 'sender_name': 'User 2', 'timestamp_ms': 1675596277579}),\n",
        "     Document(page_content='I thought you were selling the blue one!', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 4, 'sender_name': 'User 1', 'timestamp_ms': 1675595140251}),\n",
        "     Document(page_content='Im not interested in this bag. Im interested in the blue one!', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 5, 'sender_name': 'User 1', 'timestamp_ms': 1675595109305}),\n",
        "     Document(page_content='Here is $129', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 6, 'sender_name': 'User 2', 'timestamp_ms': 1675595068468}),\n",
        "     Document(page_content='', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 7, 'sender_name': 'User 2', 'timestamp_ms': 1675595060730}),\n",
        "     Document(page_content='Online is at least $100', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 8, 'sender_name': 'User 2', 'timestamp_ms': 1675595045152}),\n",
        "     Document(page_content='How much do you want?', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 9, 'sender_name': 'User 1', 'timestamp_ms': 1675594799696}),\n",
        "     Document(page_content='Goodmorning! $50 is too low.', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 10, 'sender_name': 'User 2', 'timestamp_ms': 1675577876645}),\n",
        "     Document(page_content='Hi! Im interested in your bag. Im offering $50. Let me know if you are interested. Thanks!', metadata={'source': '/Users/avsolatorio/WBG/langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 11, 'sender_name': 'User 1', 'timestamp_ms': 1675549022673})]\n",
        "\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "BLZw_teqad_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, you will see that the documents contain the metadata associated with the content we extracted."
      ],
      "metadata": {
        "id": "bPyZAIRVagoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The metadata_func\n",
        "As shown above, the metadata_func accepts the default metadata generated by the JSONLoader. This allows full control to the user with respect to how the metadata is formatted.\n",
        "\n",
        "For example, the default metadata contains the source and the seq_num keys. However, it is possible that the JSON data contain these keys as well. The user can then exploit the metadata_func to rename the default keys and use the ones from the JSON data.\n",
        "\n",
        "The example below shows how we can modify the source to only contain information of the file source relative to the langchain directory.\n",
        "\n"
      ],
      "metadata": {
        "id": "XX3tl457ajq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the metadata extraction function.\n",
        "def metadata_func(record: dict, metadata: dict) -> dict:\n",
        "\n",
        "    metadata[\"sender_name\"] = record.get(\"sender_name\")\n",
        "    metadata[\"timestamp_ms\"] = record.get(\"timestamp_ms\")\n",
        "\n",
        "    if \"source\" in metadata:\n",
        "        source = metadata[\"source\"].split(\"/\")\n",
        "        source = source[source.index(\"langchain\"):]\n",
        "        metadata[\"source\"] = \"/\".join(source)\n",
        "\n",
        "    return metadata\n",
        "\n",
        "\n",
        "loader = JSONLoader(\n",
        "    file_path='./example_data/facebook_chat.json',\n",
        "    jq_schema='.messages[]',\n",
        "    content_key=\"content\",\n",
        "    metadata_func=metadata_func\n",
        ")\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "pprint(data)"
      ],
      "metadata": {
        "id": "j3KFqCxRafDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "    [Document(page_content='Bye!', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 1, 'sender_name': 'User 2', 'timestamp_ms': 1675597571851}),\n",
        "     Document(page_content='Oh no worries! Bye', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 2, 'sender_name': 'User 1', 'timestamp_ms': 1675597435669}),\n",
        "     Document(page_content='No Im sorry it was my mistake, the blue one is not for sale', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 3, 'sender_name': 'User 2', 'timestamp_ms': 1675596277579}),\n",
        "     Document(page_content='I thought you were selling the blue one!', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 4, 'sender_name': 'User 1', 'timestamp_ms': 1675595140251}),\n",
        "     Document(page_content='Im not interested in this bag. Im interested in the blue one!', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 5, 'sender_name': 'User 1', 'timestamp_ms': 1675595109305}),\n",
        "     Document(page_content='Here is $129', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 6, 'sender_name': 'User 2', 'timestamp_ms': 1675595068468}),\n",
        "     Document(page_content='', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 7, 'sender_name': 'User 2', 'timestamp_ms': 1675595060730}),\n",
        "     Document(page_content='Online is at least $100', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 8, 'sender_name': 'User 2', 'timestamp_ms': 1675595045152}),\n",
        "     Document(page_content='How much do you want?', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 9, 'sender_name': 'User 1', 'timestamp_ms': 1675594799696}),\n",
        "     Document(page_content='Goodmorning! $50 is too low.', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 10, 'sender_name': 'User 2', 'timestamp_ms': 1675577876645}),\n",
        "     Document(page_content='Hi! Im interested in your bag. Im offering $50. Let me know if you are interested. Thanks!', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 11, 'sender_name': 'User 1', 'timestamp_ms': 1675549022673})]\n",
        "\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "gKsz7zsvaugM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pdf\n",
        "\n",
        "Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.\n",
        "\n",
        "This covers how to load PDF documents into the Document format that we use downstream."
      ],
      "metadata": {
        "id": "SzNhKANia2uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using PyPDF\n",
        "Load PDF using pypdf into array of documents, where each document contains the page content and metadata with page number."
      ],
      "metadata": {
        "id": "ZTOyIeF_a9mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypdf"
      ],
      "metadata": {
        "id": "KRxfhRDVbBmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"example_data/layout-parser-paper.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "pages[0]"
      ],
      "metadata": {
        "id": "A_B9jDlvbCX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An advantage of this approach is that documents can be retrieved with page numbers.\n",
        "\n",
        "We want to use OpenAIEmbeddings so we have to get the OpenAI API Key."
      ],
      "metadata": {
        "id": "WOfyaG9BbKPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')"
      ],
      "metadata": {
        "id": "-6OeArhTawcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings())\n",
        "docs = faiss_index.similarity_search(\"How will the community be engaged?\", k=2)\n",
        "for doc in docs:\n",
        "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
      ],
      "metadata": {
        "id": "AVgLGWyJbZfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "    9: 10 Z. Shen et al.\n",
        "    Fig. 4: Illustration of (a) the original historical Japanese document with layout\n",
        "    detection results and (b) a recreated version of the document image that achieves\n",
        "    much better character recognition recall. The reorganization algorithm rearranges\n",
        "    the tokens based on the their detect\n",
        "    3: 4 Z. Shen et al.\n",
        "    Efficient Data AnnotationC u s t o m i z e d  M o d e l  T r a i n i n gModel Cust omizationDI A Model HubDI A Pipeline SharingCommunity PlatformLa y out Detection ModelsDocument Images\n",
        "    T h e  C o r e  L a y o u t P a r s e r  L i b r a r yOCR ModuleSt or age & VisualizationLa y ou\n",
        "```\n"
      ],
      "metadata": {
        "id": "L7nMwoEdbfBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting images"
      ],
      "metadata": {
        "id": "B-Zh8H9_bkub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the rapidocr-onnxruntime package we can extract images as text as well:"
      ],
      "metadata": {
        "id": "u3AaefC2bArt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rapidocr-onnxruntime"
      ],
      "metadata": {
        "id": "GAHLtlAcbthV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"https://arxiv.org/pdf/2103.15348.pdf\", extract_images=True)\n",
        "pages = loader.load()\n",
        "pages[4].page_content"
      ],
      "metadata": {
        "id": "qrhV7cyrbuiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "'LayoutParser : A Uniﬁed Toolkit for DL-Based DIA 5\\nTable 1: Current layout detection models in the LayoutParser model zoo\\nDataset Base Model1Large Model Notes\\nPubLayNet [38] F / M M Layouts of modern scientiﬁc documents\\nPRImA [3] M - Layouts of scanned modern magazines and scientiﬁc reports\\nNewspaper [17] F - Layouts of scanned US newspapers from the 20th century\\nTableBank [18] F F Table region on modern scientiﬁc and business document\\nHJDataset [31] F / M - Layouts of history Japanese documents\\n1For each dataset, we train several models of diﬀerent sizes for diﬀerent needs (the trade-oﬀ between accuracy\\nvs. computational cost). For “base model” and “large model”, we refer to using the ResNet 50 or ResNet 101\\nbackbones [ 13], respectively. One can train models of diﬀerent architectures, like Faster R-CNN [ 28] (F) and Mask\\nR-CNN [ 12] (M). For example, an F in the Large Model column indicates it has a Faster R-CNN model trained\\nusing the ResNet 101 backbone. The platform is maintained and a number of additions will be made to the model\\nzoo in coming months.\\nlayout data structures , which are optimized for eﬃciency and versatility. 3) When\\nnecessary, users can employ existing or customized OCR models via the uniﬁed\\nAPI provided in the OCR module . 4)LayoutParser comes with a set of utility\\nfunctions for the visualization and storage of the layout data. 5) LayoutParser\\nis also highly customizable, via its integration with functions for layout data\\nannotation and model training . We now provide detailed descriptions for each\\ncomponent.\\n3.1 Layout Detection Models\\nInLayoutParser , a layout model takes a document image as an input and\\ngenerates a list of rectangular boxes for the target content regions. Diﬀerent\\nfrom traditional methods, it relies on deep convolutional neural networks rather\\nthan manually curated rules to identify content regions. It is formulated as an\\nobject detection problem and state-of-the-art models like Faster R-CNN [ 28] and\\nMask R-CNN [ 12] are used. This yields prediction results of high accuracy and\\nmakes it possible to build a concise, generalized interface for layout detection.\\nLayoutParser , built upon Detectron2 [ 35], provides a minimal API that can\\nperform layout detection with only four lines of code in Python:\\n1import layoutparser as lp\\n2image = cv2. imread (\" image_file \") # load images\\n3model = lp. Detectron2LayoutModel (\\n4 \"lp :// PubLayNet / faster_rcnn_R_50_FPN_3x / config \")\\n5layout = model . detect ( image )\\nLayoutParser provides a wealth of pre-trained model weights using various\\ndatasets covering diﬀerent languages, time periods, and document types. Due to\\ndomain shift [ 7], the prediction performance can notably drop when models are ap-\\nplied to target samples that are signiﬁcantly diﬀerent from the training dataset. As\\ndocument structures and layouts vary greatly in diﬀerent domains, it is important\\nto select models trained on a dataset similar to the test samples. A semantic syntax\\nis used for initializing the model weights in LayoutParser , using both the dataset\\nname and model name lp://<dataset-name>/<model-architecture-name> .'\n",
        "```\n"
      ],
      "metadata": {
        "id": "kwPLi88MbvRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using MathPix\n",
        "Inspired by Daniel Gross's https://gist.github.com/danielgross/3ab4104e14faccc12b49200843adab21\n",
        "\n"
      ],
      "metadata": {
        "id": "diQHKvwUb5fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import MathpixPDFLoader"
      ],
      "metadata": {
        "id": "AB6ziSQvbz-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = MathpixPDFLoader(\"example_data/layout-parser-paper.pdf\")"
      ],
      "metadata": {
        "id": "aO8-2QxUb_HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()"
      ],
      "metadata": {
        "id": "QoSp2l7ecAv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Unstructured"
      ],
      "metadata": {
        "id": "GpEM5zElcCqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
        "\n",
        "loader = UnstructuredPDFLoader(\"example_data/layout-parser-paper.pdf\")\n",
        "\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "6SSbdfQQcG3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retain Elements\n",
        "Under the hood, Unstructured creates different \"elements\" for different chunks of text. By default we combine those together, but you can easily keep that separation by specifying mode=\"elements\"."
      ],
      "metadata": {
        "id": "Wjd-X8gccNg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = UnstructuredPDFLoader(\"example_data/layout-parser-paper.pdf\", mode=\"elements\")\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "data[0]"
      ],
      "metadata": {
        "id": "6FR3_EqzcP9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fetching remote PDFs using Unstructured\n",
        "\n",
        "This covers how to load online PDFs into a document format that we can use downstream. This can be used for various online PDF sites such as https://open.umn.edu/opentextbooks/textbooks/ and https://arxiv.org/archive/\n",
        "\n",
        "Note: all other PDF loaders can also be used to fetch remote PDFs, but `OnlinePDFLoader` is a legacy function, and works specifically with `UnstructuredPDFLoader`."
      ],
      "metadata": {
        "id": "0VnT2ttncVNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import OnlinePDFLoader\n",
        "\n",
        "loader = OnlinePDFLoader(\"https://arxiv.org/pdf/2302.03803.pdf\")\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "id": "YnbFQuHxcoWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using PyPDFium2"
      ],
      "metadata": {
        "id": "t6eVoLUfcuuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFium2Loader\n",
        "\n",
        "loader = PyPDFium2Loader(\"example_data/layout-parser-paper.pdf\")\n",
        "\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "ILkzT_rmcxvH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using PDFMiner"
      ],
      "metadata": {
        "id": "LiIjZ9rIc5_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PDFMinerLoader\n",
        "\n",
        "loader = PDFMinerLoader(\"example_data/layout-parser-paper.pdf\")\n",
        "\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "DiNcmwTSc0qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Using PDFMiner to generate HTML text\n",
        "This can be helpful for chunking texts semantically into sections as the output html content can be parsed via BeautifulSoup to get more structured and rich information about font size, page numbers, PDF headers/footers, etc."
      ],
      "metadata": {
        "id": "Aue49KlfdJRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PDFMinerPDFasHTMLLoader\n",
        "\n",
        "loader = PDFMinerPDFasHTMLLoader(\"example_data/layout-parser-paper.pdf\")\n",
        "\n",
        "data = loader.load()[0]   # entire PDF is loaded as a single Document\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(data.page_content,'html.parser')\n",
        "content = soup.find_all('div')\n",
        "\n",
        "import re\n",
        "cur_fs = None\n",
        "cur_text = ''\n",
        "snippets = []   # first collect all snippets that have the same font size\n",
        "for c in content:\n",
        "    sp = c.find('span')\n",
        "    if not sp:\n",
        "        continue\n",
        "    st = sp.get('style')\n",
        "    if not st:\n",
        "        continue\n",
        "    fs = re.findall('font-size:(\\d+)px',st)\n",
        "    if not fs:\n",
        "        continue\n",
        "    fs = int(fs[0])\n",
        "    if not cur_fs:\n",
        "        cur_fs = fs\n",
        "    if fs == cur_fs:\n",
        "        cur_text += c.text\n",
        "    else:\n",
        "        snippets.append((cur_text,cur_fs))\n",
        "        cur_fs = fs\n",
        "        cur_text = c.text\n",
        "snippets.append((cur_text,cur_fs))\n",
        "# Note: The above logic is very straightforward. One can also add more strategies such as removing duplicate snippets (as\n",
        "# headers/footers in a PDF appear on multiple pages so if we find duplicates it's safe to assume that it is redundant info)"
      ],
      "metadata": {
        "id": "-7RJBmLfdMx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "cur_idx = -1\n",
        "semantic_snippets = []\n",
        "# Assumption: headings have higher font size than their respective content\n",
        "for s in snippets:\n",
        "    # if current snippet's font size > previous section's heading => it is a new heading\n",
        "    if not semantic_snippets or s[1] > semantic_snippets[cur_idx].metadata['heading_font']:\n",
        "        metadata={'heading':s[0], 'content_font': 0, 'heading_font': s[1]}\n",
        "        metadata.update(data.metadata)\n",
        "        semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
        "        cur_idx += 1\n",
        "        continue\n",
        "\n",
        "    # if current snippet's font size <= previous section's content => content belongs to the same section (one can also create\n",
        "    # a tree like structure for sub sections if needed but that may require some more thinking and may be data specific)\n",
        "    if not semantic_snippets[cur_idx].metadata['content_font'] or s[1] <= semantic_snippets[cur_idx].metadata['content_font']:\n",
        "        semantic_snippets[cur_idx].page_content += s[0]\n",
        "        semantic_snippets[cur_idx].metadata['content_font'] = max(s[1], semantic_snippets[cur_idx].metadata['content_font'])\n",
        "        continue\n",
        "\n",
        "    # if current snippet's font size > previous section's content but less than previous section's heading than also make a new\n",
        "    # section (e.g. title of a PDF will have the highest font size but we don't want it to subsume all sections)\n",
        "    metadata={'heading':s[0], 'content_font': 0, 'heading_font': s[1]}\n",
        "    metadata.update(data.metadata)\n",
        "    semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
        "    cur_idx += 1"
      ],
      "metadata": {
        "id": "BD80rGkHdVna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_snippets[4]"
      ],
      "metadata": {
        "id": "HLj0AftCdYc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using PyMuPDF\n",
        "This is the fastest of the PDF parsing options, and contains detailed metadata about the PDF and its pages, as well as returns one document per page.\n"
      ],
      "metadata": {
        "id": "swYh7ptXdZ2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader(\"example_data/layout-parser-paper.pdf\")\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "data[0]"
      ],
      "metadata": {
        "id": "IKZHpbXwdfju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, you can pass along any of the options from the PyMuPDF documentation as keyword arguments in the load call, and it will be pass along to the get_text() call."
      ],
      "metadata": {
        "id": "6ZXr3WRLdssx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PyPDF Directory"
      ],
      "metadata": {
        "id": "jwB3j4sWd4pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "\n",
        "loader = PyPDFDirectoryLoader(\"example_data/\")\n",
        "\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "iFVthEyWdlir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using PDFPlumber\n",
        "Like PyMuPDF, the output Documents contain detailed metadata about the PDF and its pages, and returns one document per page."
      ],
      "metadata": {
        "id": "C1ermrndeEYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PDFPlumberLoader\n",
        "\n",
        "loader = PDFPlumberLoader(\"example_data/layout-parser-paper.pdf\")\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "data[0]"
      ],
      "metadata": {
        "id": "7x11cuMveDDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using AmazonTextractPDFParser\n",
        "The AmazonTextractPDFLoader calls the Amazon Textract Service to convert PDFs into a Document structure. The loader does pure OCR at the moment, with more features like layout support planned, depending on demand. Single and multi-page documents are supported with up to 3000 pages and 512 MB of size.\n",
        "\n",
        "For the call to be successful an AWS account is required, similar to the AWS CLI requirements.\n",
        "\n",
        "Besides the AWS configuration, it is very similar to the other PDF loaders, while also supporting JPEG, PNG and TIFF and non-native PDF formats."
      ],
      "metadata": {
        "id": "m_A9vWwzeOoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import AmazonTextractPDFLoader\n",
        "loader = AmazonTextractPDFLoader(\"example_data/alejandro_rosalez_sample-small.jpeg\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "gVTEywfaeXIA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}